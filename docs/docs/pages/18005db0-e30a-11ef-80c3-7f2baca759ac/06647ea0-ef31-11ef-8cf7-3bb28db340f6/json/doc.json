[{"type":"text","level":1,"children":[{"type":"text","level":0,"text":"接入DeepSeek，人工智能对话"}]},{"type":"text","level":2,"children":[{"type":"text","level":0,"text":"功能描述"}]},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"增加一种人工智能对话窗口，在消息列表查询时，默认为私聊或者群聊，现在增加一个人工智能对话类型。"}]},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"如果是人工智能对话类型，则打开人工智能对话窗口。"}]},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"进入聊天窗口可以选择ai模型，默认deepseek。"}]},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"在好友列表增加一个人工智能的按钮，点击人工智能创建一个人工智能对话窗口。"}]},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"人工智能对话窗口使用一个新视图实现，参考ChatPage和ChatController，使用类似的方式实现，命名为AiChatPage和AiChatController。"}]},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"将AiChatPage放入路由，如果对话窗口信息是人工智能，则通过路由打开AiChatPage。"}]},{"type":"text","level":2,"itemType":"text","children":[{"type":"text","level":0,"text":"使用openai_dart插件，0.4.5版本"}]},{"type":"text","level":0,"itemType":"text","children":[{"type":"text","level":0,"text":"openai_dart文档地址：https://pub.dev/packages/openai_dart"}]},{"type":"text","level":0,"itemType":"text","children":[{"type":"text","level":0,"text":"部分文档如下："}]},{"type":"title","level":0,"children":[{"type":"text","level":0,"text":"Authentication"}]},{"type":"code","level":0,"code":"final openaiApiKey = Platform.environment['OPENAI_API_KEY'];\nfinal client = OpenAIClient(apiKey: openaiApiKey);","language":"dart"},{"type":"code","level":0,"code":"final client = OpenAIClient(\n  apiKey: openaiApiKey,\n  organization: 'org-dtDDtkEGoFccn5xaP5W1p3Rr',\n);","language":"dart"},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"Chat"}]},{"type":"code","level":0,"code":"final res = await client.createChatCompletion(\n  request: CreateChatCompletionRequest(\n    model: ChatCompletionModel.modelId('gpt-4o'),\n    messages: [\n      ChatCompletionMessage.system(\n        content: 'You are a helpful assistant.',\n      ),\n      ChatCompletionMessage.user(\n        content: ChatCompletionUserMessageContent.string('Hello!'),\n      ),\n    ],\n    temperature: 0,\n  ),\n);\nprint(res.choices.first.message.content);\n// Hello! How can I assist you today?","language":"dart"},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"Stream chat completion:","color":4283058762,"bold":false,"italic":false}]},{"type":"code","level":0,"code":"final stream = client.createChatCompletionStream(\n  request: CreateChatCompletionRequest(\n    model: ChatCompletionModel.modelId('gpt-4o'),\n    messages: [\n      ChatCompletionMessage.system(\n        content:\n            'You are a helpful assistant that replies only with numbers '\n            'in order without any spaces or commas',\n      ),\n      ChatCompletionMessage.user(\n        content: ChatCompletionUserMessageContent.string(\n          'List the numbers from 1 to 9',\n        ),\n      ),\n    ],\n  ),\n);\nawait for (final res in stream) {\n  print(res.choices.first.delta.content);\n}\n// 123\n// 456\n// 789\n","language":"dart"},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"Multi-modal prompt (text/image/audio)","color":4283058762,"bold":false,"italic":false}]},{"type":"code","level":0,"code":"final res = await client.createChatCompletion(\n  request: CreateChatCompletionRequest(\n    model: ChatCompletionModel.model(\n      ChatCompletionModels.gpt4VisionPreview,\n    ),\n    messages: [\n      ChatCompletionMessage.system(\n        content: 'You are a helpful assistant.',\n      ),\n      ChatCompletionMessage.user(\n        content: ChatCompletionUserMessageContent.parts(\n          [\n            ChatCompletionMessageContentPart.text(\n              text: 'What fruit is this?',\n            ),\n            ChatCompletionMessageContentPart.image(\n              imageUrl: ChatCompletionMessageImageUrl(\n                url: 'https://upload.wikimedia.org/wikipedia/commons/9/92/95apple.jpeg',\n              ),\n            ),\n          ],\n        ),\n      ),\n    ],\n  ),\n);\nprint(res.choices.first.message.content);\n// The fruit in the image is an apple.","language":"dart"},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"Or provide the base64-encoded image:","color":4283058762,"bold":false,"italic":false}]},{"type":"code","level":0,"code":"//...\nChatCompletionMessage.user(\n  content: ChatCompletionUserMessageContent.parts(\n    [\n      ChatCompletionMessageContentPart.text(\n        text: 'What fruit is this?',\n      ),\n      ChatCompletionMessageContentPart.image(\n        imageUrl: ChatCompletionMessageImageUrl(\n          url: '/9j/4AAQSkZJRgABAQAAAQABAAD/2wB...P3s/XHQ8cE/nmiupbL0+fz/r/MjnSbsr69/Rdu1j//2Q==',\n          detail: ChatCompletionMessageImageDetail.high,\n        ),\n      ),\n    ],\n  ),\n),\n//...","language":"dart"},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"In addition to generating text and images, some models enable you to generate a spoken audio response to a prompt","color":4283058762,"bold":false,"italic":false},{"type":"text","level":0,"text":":","color":4283058762,"bold":false,"italic":false}]},{"type":"code","level":0,"code":"final res = await client.createChatCompletion(\n  request: CreateChatCompletionRequest(\n    model: ChatCompletionModel.model(\n      ChatCompletionModels.gpt4oAudioPreview,\n    ),\n    modalities: [\n      ChatCompletionModality.text,\n      ChatCompletionModality.audio,\n    ],\n    audio: ChatCompletionAudioOptions(\n      voice: ChatCompletionAudioVoice.alloy,\n      format: ChatCompletionAudioFormat.wav,\n    ),\n    messages: [\n      ChatCompletionMessage.user(\n        content: ChatCompletionUserMessageContent.string(\n          'Is a golden retriever a good family dog?',\n        ),\n      ),\n    ],\n  ), \n);\nfinal choice = res.choices.first;\nfinal audio = choice.message.audio;\nprint(audio?.id);\nprint(audio?.expiresAt);\nprint(audio?.transcript);\nprint(audio?.data);","language":"dart"},{"type":"text","level":0,"children":[{"type":"text","level":0,"text":"And to use audio inputs to prompt the model:","color":4283058762,"bold":false,"italic":false}]},{"type":"code","level":0,"code":"final res = await client.createChatCompletion(\n  request: CreateChatCompletionRequest(\n    model: ChatCompletionModel.model(\n      ChatCompletionModels.gpt4oAudioPreview,\n    ),\n    modalities: [\n      ChatCompletionModality.text,\n      ChatCompletionModality.audio,\n    ],\n    audio: ChatCompletionAudioOptions(\n      voice: ChatCompletionAudioVoice.alloy,\n      format: ChatCompletionAudioFormat.wav,\n    ),\n    messages: [\n      ChatCompletionMessage.user(\n        content: ChatCompletionUserMessageContent.parts([\n          ChatCompletionMessageContentPart.text(\n            text: 'Do what the recording says',\n          ),\n          ChatCompletionMessageContentPart.audio(\n            inputAudio: ChatCompletionMessageInputAudio(\n              data: 'UklGRoYZAQBXQVZFZm10I...//X//v8FAOj/GAD+/7z/',\n              format: ChatCompletionMessageInputAudioFormat.wav,\n            ),\n          ),\n        ]),\n      ),\n    ],\n  );\n);\nfinal choice = res.choices.first;\nfinal audio = choice.message.audio;\nprint(audio?.id);\nprint(audio?.expiresAt);\nprint(audio?.transcript);\nprint(audio?.data);\n","language":"dart"},{"type":"text","level":0},{"type":"text","level":0}]